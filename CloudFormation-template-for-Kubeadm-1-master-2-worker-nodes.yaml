# Copyright 2017 by the contributors
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.

---
AWSTemplateFormatVersion: '2010-09-09'
Description: ' Kubernetes AWS CloudFormation Template: Create a Kubernetes
  cluster master and nodes in an existing aws VPC.'

Parameters:

#  ClusterName:
#    Description: Enter a string, that will be use as Kubeadm cluster name.
#    Type: String

  # Required. Calls for the name of an existing EC2 KeyPair, to enable SSH access to the instances
  # http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html
  KeyName:
    Description: Existing EC2 KeyPair for SSH access.
    Type: AWS::EC2::KeyPair::KeyName
    ConstraintDescription: must be the name of an existing EC2 KeyPair.

  VPCID:
    Description: Existing VPC to use for this cluster.
    Type: AWS::EC2::VPC::Id

  ClusterSubnetId:
    Description: Existing subnet to use for this cluster. Must belong to the Availability Zone above.
    Type: AWS::EC2::Subnet::Id

  AvailabilityZone:
    Description: The Availability Zone for this cluster. VMware recommends
      that you run one cluster per AZ and use tooling to coordinate across AZs.
    Type: AWS::EC2::AvailabilityZone::Name
    ConstraintDescription: must be the name of an AWS Availability Zone

  # https://aws.amazon.com/ec2/instance-types/
  InstanceType:
    Description: EC2 instance type for the cluster.
    Type: String
    Default: t2.medium
    AllowedValues:
    - t3.medium
    - t2.medium
    - t2.large
    - t3.large
    - c4.2xlarge
    - c4.4xlarge
    - c4.8xlarge
    - c4.large
    - c4.xlarge
    - c5.18xlarge
    - c5.2xlarge
    - c5.4xlarge
    - c5.9xlarge
    - c5.large
    - c5.xlarge
    - c5d.large
    - c5d.xlarge
    - c5d.2xlarge
    - c5d.4xlarge
    - c5d.9xlarge
    - c5d.18xlarge
    - c5n.large
    - c5n.xlarge
    - c5n.2xlarge
    - c5n.4xlarge
    - c5n.9xlarge
    - c5n.18xlarge
    - d2.xlarge
    - d2.2xlarge
    - d2.4xlarge
    - d2.8xlarge
    - g3.16xlarge
    - f1.2xlarge
    - f1.4xlarge
    - f1.16xlarge
    - g3.4xlarge
    - g3.8xlarge
    - g3.16xlarge
    - g3s.xlarge
    - h1.2xlarge
    - h1.4xlarge
    - h1.8xlarge
    - h1.16xlarge
    - i3.16xlarge
    - i3.2xlarge
    - i3.4xlarge
    - i3.8xlarge
    - i3.xlarge
    - i3.large
    - i3.metal
    - i3.xlarge
    - m4.10xlarge
    - m4.16xlarge
    - m4.2xlarge
    - m4.4xlarge
    - m4.large
    - m4.xlarge
    - m5.12xlarge
    - m5.24xlarge
    - m5.2xlarge
    - m5.4xlarge
    - m5.large
    - m5.xlarge
    - m5a.12xlarge
    - m5a.24xlarge
    - m5a.2xlarge
    - m5a.large
    - m5a.xlarge
    - m5d.12xlarge
    - m5d.24xlarge
    - m5d.2xlarge
    - m5d.4xlarge
    - m5d.large
    - m5d.xlarge
    - p2.16xlarge
    - p2.8xlarge
    - p2.xlarge
    - p3.16xlarge
    - p3.2xlarge
    - p3.8xlarge
    - p3dn.24xlarge
    - r3.2xlarge
    - r3.4xlarge
    - r3.8xlarge
    - r3.large
    - r3.xlarge
    - r4.16xlarge
    - r4.2xlarge
    - r4.4xlarge
    - r4.8xlarge
    - r4.large
    - r4.xlarge
    - r5.large
    - r5.xlarge
    - r5.2xlarge
    - r5.4xlarge
    - r5.12xlarge
    - r5.24xlarge
    - r5a.large
    - r5a.xlarge
    - r5a.2xlarge
    - r5a.4xlarge
    - r5a.12xlarge
    - r5a.24xlarge
    - r5d.xlarge
    - r5d.2xlarge
    - r5d.4xlarge
    - r5d.12xlarge
    - r5d.24xlarge
    - x1.16xlarge
    - x1.32xlarge
    - x1e.xlarge
    - x1e.2xlarge
    - x1e.4xlarge
    - x1e.8xlarge
    - x1e.16xlarge
    - x1e.32xlarge
    - u-6tb1.metal
    - u-9tb1.metal
    - u-12tb1.metal
    - z1d.large
    - z1d.xlarge
    - z1d.2xlarge
    - z1d.3xlarge
    - z1d.6xlarge
    - z1d.12xlarge
    ConstraintDescription: must be a valid Current Generation (non-burstable) EC2 instance type.

  # Specifies the size of the root disk for all EC2 instances, including master
  # and nodes.
  DiskSizeGb:
    Description: 'Size of the root disk for the EC2 instances, in GiB.  Default: 40'
    Default: 40
    Type: Number
    MinValue: 8
    MaxValue: 1024

  SSHLocation:
    Description: CIDR block (IP address range) to allow SSH access to the
      instances. Use 0.0.0.0/0 to allow access from all locations.
    Type: String
    MinLength: '9'
    MaxLength: '18'
    Default: '0.0.0.0/0'
    AllowedPattern: "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})"
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.

  KubernetesVersion:
    Description: Version of Kubernetes you will like installed for both master and nodes.
    Type: String
    MinLength: '3'
    MaxLength: '6'
    Default: "1.21.0"

  K8sNodeCapacity:
    Default: '2'
    Description: Initial number of Kubernetes nodes (1-70).
    Type: Number
    MinValue: '1'
    MaxValue: '70'
    ConstraintDescription: must be between 1 and 70 EC2 instances.

#Conditions:
#  AssociationProvidedCondition:
#    Fn::Equals:
#      - !Ref AWS::StackName

Mappings:
  # AMIs for ubuntu 18.04 across regions
  RegionMap:
    ap-northeast-1:
      '64': ami-0fe22bffdec36361c
    ap-northeast-2:
      '64': ami-0ba5cd124d7a79612
    ap-south-1:
      '64': ami-04bde106886a53080
    ap-southeast-1:
      '64': ami-055147723b7bca09a
    ap-southeast-2:
      '64': ami-0f39d06d145e9bb63
    eu-central-1:
      '64': ami-0b1deee75235aa4bb
    eu-west-1:
      '64': ami-0943382e114f188e8
    eu-west-2:
      '64': ami-09a56048b08f94cdf
    eu-west-3:
      '64': ami-06602da18c878f98d
    us-east-2:
      '64': ami-0b9064170e32bde34
    us-west-1:
      '64': ami-07b068f843ec78e72
    us-west-2:
      '64': ami-090717c950a5c34d3
    us-east-1:
      '64': ami-0747bdcabd34c712a
    af-south-1:
      '64': ami-0e93b3dda12646545


# Resources are the AWS services we want to actually create as part of the Stack
Resources:
  ClusterInfoBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub config-file-${AWS::StackName}
      AccessControl: Private
      Tags:
      - Key: { "Fn::Sub": "kubernetes.io/cluster/${AWS::StackName}" }
        Value: owned

  # This is an EC2 instance that will serve as our master node
  K8sMasterInstance:
    Type: AWS::EC2::Instance
    Properties:
      # Where the EC2 instance gets deployed geographically
      AvailabilityZone: !Ref AvailabilityZone
      # Refers to the MasterInstanceProfile resource, which applies the IAM role for the master instance
      # The IAM role allows us to create further AWS resources (like an EBS drive) from the cluster
      # This is needed for the Kubernetes-AWS cloud-provider integration
      IamInstanceProfile: !Ref MasterInstanceProfile
      # Type of instance; the default is m3.medium
      InstanceType: !Ref InstanceType
      # Adds our SSH key to the instance
      KeyName: !Ref KeyName
      NetworkInterfaces:
      - DeleteOnTermination: true
        DeviceIndex: '0'
        SubnetId: !Ref ClusterSubnetId
        # Joins the ClusterSecGroup Security Group for cluster communication and SSH access
        # The ClusterSecGroupCrossTalk rules allow all instances in the same stack to communicate internally
        # The ClusterSecGroupAllow22 rules allow external communication on port 22 from a chosen CIDR range
        # The ClusterSecGroupAllow6443FromLB rules allow HTTPS access to the load balancer on port 6443
        GroupSet:
        - !Ref ClusterSecGroup
      Tags:
      - Key: Name
        Value: k8s-master
      - Key: KubernetesCluster
        Value: { "Fn::Sub": "${AWS::StackName}" }
        # Also tag it with kubernetes.io/cluster/clustername=owned, which is the newer convention for cluster resources
      - Key: { "Fn::Sub": "kubernetes.io/cluster/${AWS::StackName}" }
        Value: 'owned'
      # http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html#cfn-ec2-instance-imageid
      ImageId:
        Fn::FindInMap:
        - RegionMap
        - !Ref AWS::Region
        - '64'
      BlockDeviceMappings:
      - DeviceName: '/dev/sda1'
        Ebs:
          VolumeSize: !Ref DiskSizeGb
          VolumeType: gp2
      # The userdata script is launched on startup, but contains only the commands that call out to cfn-init, which runs
      # the commands in the metadata above, and cfn-signal, which signals when the initialization is complete.
      UserData:
        Fn::Base64:
          Fn::Sub:
            - |
              #!/bin/bash -xe
              cat <<EOF | tee /etc/modules-load.d/containerd.conf
              overlay
              br_netfilter
              EOF

              modprobe overlay && modprobe br_netfilter
              cat <<EOF | tee /etc/sysctl.d/99-kubernetes-cri.conf
              net.bridge.bridge-nf-call-iptables = 1
              net.ipv4.ip_forward = 1
              net.bridge.bridge-nf-call-ip6tables = 1
              EOF

              sysctl --system
              apt-get update && apt-get install -y containerd
              mkdir -p /etc/containerd && containerd config default | tee /etc/containerd/config.toml
              systemctl restart containerd
              systemctl status containerd

              swapoff -a
              sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
              apt-get update && apt-get install -y apt-transport-https curl
              curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

              cat << EOF | tee /etc/apt/sources.list.d/kubernetes.list
              deb https://apt.kubernetes.io/ kubernetes-xenial main
              EOF

              apt-get update -y
              apt install awscli -y
              apt-get install -y kubectl="${KubernetesVersion}"-00 kubeadm="${KubernetesVersion}"-00 kubelet="${KubernetesVersion}"-00
              apt-mark hold kubelet kubectl kubeadm

              #export HOSTNAME="$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)"

              /bin/cat > /etc/systemd/system/kubelet.service.d/10-hostname.conf <<EOF
              [Service]
              Environment="KUBELET_EXTRA_ARGS= --hostname-override=$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname) --cloud-provider=aws --authentication-token-webhook=true"
              EOF

              systemctl daemon-reload

              apt-get update -y

              apt-get install -y python-setuptools

              mkdir -p /opt/aws/bin

              wget https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz

              python -m easy_install --script-dir /opt/aws/bin aws-cfn-bootstrap-latest.tar.gz

              apt-get update -y

              cat >/tmp/kubeadm.yaml <<EOF
              ---
              apiVersion: kubeadm.k8s.io/v1beta1
              kind: InitConfiguration
              bootstrapTokens:
              - groups:
                - "system:bootstrappers:kubeadm:default-node-token"
                token: "gora21.cxmfb878wqhddry0"
                ttl: "0s"
                usages:
                - signing
                - authentication
              nodeRegistration:
                name: "$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)"
                kubeletExtraArgs:
                  cloud-provider: "aws"
              ---
              apiVersion: kubeadm.k8s.io/v1beta1
              kind: ClusterConfiguration
              kubernetesVersion: "${KubernetesVersion}"
              apiServer:
                timeoutForControlPlane: 4m0s
                certSANs:
                - "$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)"
                extraArgs:
                  cloud-provider: "aws"
              clusterName: kubernetes
              controlPlaneEndpoint: "$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)"
              controllerManager:
                extraArgs:
                  cloud-provider: "aws"
                  allocate-node-cidrs: "false"
              networking:
                podSubnet: 192.168.0.0/16
              EOF

              kubeadm init --config /tmp/kubeadm.yaml

              # applying calico CNI to cluster
              kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f https://docs.projectcalico.org/manifests/calico.yaml

              # And for local debugging, set up ~/.kube/config for the main user account on
              # the master.
              mkdir -p /home/ubuntu/.kube
              cp /etc/kubernetes/admin.conf /home/ubuntu/.kube/config
              chown -R ubuntu:ubuntu /home/ubuntu/.kube

              #export ClusterInfoBucket=config-'${AWS::StackName}'-"${KubernetesVersion}"

              # Store kubeadm config file in created S3 bucket
              kubectl --kubeconfig=/etc/kubernetes/admin.conf get cm -n kube-public cluster-info -o "jsonpath={.data.kubeconfig}" | aws s3 cp - s3://${ClusterInfoBucket}/cluster-info.yaml

              # Signal the status from cfn-signal
              /opt/aws/bin/cfn-signal -e $? --stack '${AWS::StackName}' --region '${AWS::Region}' --resource K8sMasterInstance

              # substitute Cluster config bucket name variable in userdata with value from resource name.
            - ClusterInfoBucket: { "Fn::Select" : [ "0", { "Fn::Split": [".", {"Fn::GetAtt": "ClusterInfoBucket.DomainName"}]}] }

    CreationPolicy:
      ResourceSignal:
        Timeout: PT10M

  # IAM role for the master node http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html
  MasterRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      # IAM policy for the master node that allows specific AWS resource listing and creation
      # More permissive than the node role (it allows load balancer creation)
      # http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html
      Policies:
      - PolicyName: master
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ec2:*
            - elasticloadbalancing:*
            - ecr:GetAuthorizationToken
            - ecr:BatchCheckLayerAvailability
            - ecr:GetDownloadUrlForLayer
            - ecr:GetRepositoryPolicy
            - ecr:DescribeRepositories
            - ecr:ListImages
            - ecr:BatchGetImage
            - autoscaling:DescribeAutoScalingGroups
            - autoscaling:UpdateAutoScalingGroup
            Resource: "*"

      - PolicyName: discoverBucketWrite
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:PutObject
            Resource: !Sub "arn:${AWS::Partition}:s3:::${ClusterInfoBucket}/cluster-info.yaml"

  # Bind the MasterRole to a profile for the VM instance.
  MasterInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - !Ref MasterRole

  K8sNodeGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn: K8sMasterInstance
    CreationPolicy:
      ResourceSignal:
        # Ensure at least <K8sNodeCapacity> nodes have signaled success before
        # this resource is considered created.
        Count: !Ref K8sNodeCapacity
        Timeout: PT10M
    Properties:
      # Where the EC2 instance gets deployed geographically
      AvailabilityZones:
      - !Ref AvailabilityZone
      # Refers to the K8sNodeCapacity parameter, which specifies the number of nodes (1-70)
      DesiredCapacity: !Ref K8sNodeCapacity
      # Refers to the LaunchConfig, which has specific config details for the EC2 instances
      LaunchConfigurationName: !Ref LaunchConfig
      # More cluster sizing
      MinSize: '1'
      MaxSize: '70'
      # VPC Zone Identifier is the subnets to put the hosts in
      VPCZoneIdentifier:
        - !Ref ClusterSubnetId
      # Designates names for these EC2 instances that will appear in the instances list (k8s-node)
      # Tags each node with KubernetesCluster=<stackname> or chosen value (needed for cloud-provider's IAM roles)
      Tags:
      - Key: Name
        Value: k8s-node
        PropagateAtLaunch: true
      - Key: KubernetesCluster
        Value: { "Fn::Sub": "${AWS::StackName}" }
        PropagateAtLaunch: true
        # Also tag it with kubernetes.io/cluster/clustername=owned, which is the newer convention for cluster resources
      - Key: { "Fn::Sub": "kubernetes.io/cluster/${AWS::StackName}" }
        Value: 'owned'
        PropagateAtLaunch: true
    # Tells the group how many instances to update at a time, if an update is applied
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: 1
        MaxBatchSize: 1

  # This tells AWS what kinds of servers we want in our Auto Scaling Group
  LaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      # Refers to the NodeInstanceProfile resource, which applies the IAM role for the nodes
      # The IAM role allows us to create further AWS resources (like an EBS drive) from the cluster
      # This is needed for the Kubernetes-AWS cloud-provider integration
      IamInstanceProfile: !Ref NodeInstanceProfile
      # http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html#cfn-ec2-instance-imageid
      ImageId:
        Fn::FindInMap:
        - RegionMap
        - !Ref AWS::Region
        - '64'
      BlockDeviceMappings:
      - DeviceName: '/dev/sda1'
        Ebs:
          VolumeSize: !Ref DiskSizeGb
          VolumeType: gp2
      # Type of instance; the default is m3.medium
      InstanceType: !Ref InstanceType
      # Adds our SSH key to the instance
      KeyName: !Ref KeyName
      # Join the cluster security group so that we can customize the access
      # control (See the ClusterSecGroup resource for details)
      SecurityGroups:
      - !Ref ClusterSecGroup
      # The userdata script is launched on startup, but contains only the commands that call out to cfn-init, which runs
      # the commands in the metadata above, and cfn-signal, which signals when the initialization is complete.
      UserData:
        Fn::Base64:
          Fn::Sub:
            - |
              #!/bin/bash -xe
              cat <<EOF | tee /etc/modules-load.d/containerd.conf
              overlay
              br_netfilter
              EOF

              modprobe overlay && modprobe br_netfilter
              cat <<EOF | tee /etc/sysctl.d/99-kubernetes-cri.conf
              net.bridge.bridge-nf-call-iptables = 1
              net.ipv4.ip_forward = 1
              net.bridge.bridge-nf-call-ip6tables = 1
              EOF

              sysctl --system
              apt-get update && apt-get install -y containerd
              mkdir -p /etc/containerd && containerd config default | tee /etc/containerd/config.toml
              systemctl restart containerd
              systemctl status containerd

              swapoff -a
              sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
              apt-get update && apt-get install -y apt-transport-https curl
              curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

              cat << EOF | tee /etc/apt/sources.list.d/kubernetes.list
              deb https://apt.kubernetes.io/ kubernetes-xenial main
              EOF

              apt-get update -y
              apt install awscli -y
              apt-get install -y kubectl="${KubernetesVersion}"-00 kubeadm="${KubernetesVersion}"-00 kubelet="${KubernetesVersion}"-00
              apt-mark hold kubelet kubectl kubeadm

              #export HOSTNAME="$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)"

              /bin/cat > /etc/systemd/system/kubelet.service.d/10-hostname.conf <<EOF
              [Service]
              Environment="KUBELET_EXTRA_ARGS= --hostname-override=$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname) --cloud-provider=aws --authentication-token-webhook=true"
              EOF

              systemctl daemon-reload

              apt-get update -y

              apt-get install -y python-setuptools

              mkdir -p /opt/aws/bin

              wget https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz

              python -m easy_install --script-dir /opt/aws/bin aws-cfn-bootstrap-latest.tar.gz

              apt-get update -y

              # Get a copy of Kubeadm config from created S3 bucket
              aws s3 cp s3://${ClusterInfoBucket}/cluster-info.yaml /tmp/cluster-info.yaml && kubeadm join --node-name="$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)" --token="gora21.cxmfb878wqhddry0" --discovery-file=/tmp/cluster-info.yaml

              # Signal the status from cfn-signal
              /opt/aws/bin/cfn-signal -e $? --stack '${AWS::StackName}' --region '${AWS::Region}' --resource K8sNodeGroup

              # substitute Cluster config bucket name variable in userdata with value from resource name.
            - ClusterInfoBucket: { "Fn::Select" : [ "0", { "Fn::Split": [".", {"Fn::GetAtt": "ClusterInfoBucket.DomainName"}]}] }

  ClusterSecGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for all machines in the cluster
      VpcId: !Ref VPCID
      # Security Groups must be tagged with KubernetesCluster=<cluster> so that
      # they can coexist in the same VPC
      Tags:
      - Key: KubernetesCluster
        Value: { "Fn::Sub": "${AWS::StackName}" }
      - Key: { "Fn::Sub": "kubernetes.io/cluster/${AWS::StackName}" }
        Value: 'owned'
      - Key: Name
        Value: k8s-cluster-security-group

  # Permissions we add to the main security group:
  # - Ensure cluster machines can talk to one anotherKubeadmToken
  ClusterSecGroupCrossTalk:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ClusterSecGroup
      SourceSecurityGroupId: !Ref ClusterSecGroup
      IpProtocol: '-1'
      FromPort: 0
      ToPort: 65535

  # - Open up port 22 for SSH into each machine
  # The allowed locations are chosen by the user in the SSHLocation parameter
  ClusterSecGroupAllow22:
    Metadata:
      Comment: Open up port 22 for SSH into each machine
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ClusterSecGroup
      IpProtocol: tcp
      FromPort: 22
      ToPort: 22
      CidrIp: !Ref SSHLocation

  # IAM role for nodes http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html
  NodeRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      # IAM policy for nodes that allows specific AWS resource listing and creation
      # http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html
      Policies:
      - PolicyName: node
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - ec2:Describe*
            - ecr:GetAuthorizationToken
            - ecr:BatchCheckLayerAvailability
            - ecr:GetDownloadUrlForLayer
            - ecr:GetRepositoryPolicy
            - ecr:DescribeRepositories
            - ecr:ListImages
            - ecr:BatchGetImage
            Resource: "*"

      - PolicyName: discoverBucketWrite
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            Resource: !Sub "arn:${AWS::Partition}:s3:::${ClusterInfoBucket}/cluster-info.yaml"

  # Resource that creates the node IAM role
  NodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - !Ref NodeRole

Outputs:
  MasterInstanceId:
    Description: InstanceId of the master EC2 instance.
    Value: !Ref K8sMasterInstance

  MasterPrivateIp:
    Description: Private IP address of the master.
    Value: !GetAtt K8sMasterInstance.PrivateIp

  NodeGroupInstanceId:
    Description: InstanceId of the newly-created NodeGroup.
    Value: !Ref K8sNodeGroup

  JoinNodes:
    Description: Command to join more nodes to this cluster.
    Value: !Sub "aws s3 cp s3://${ClusterInfoBucket}/cluster-info.yaml /tmp/cluster-info.yaml && kubeadm join --node-name=\"$(hostname -f 2>/dev/null || curl http://169.254.169.254/latest/meta-data/local-hostname)\" --token=gora21.cxmfb878wqhddry0 --discovery-file=/tmp/cluster-info.yaml"
